# ðŸ“š Kubernetes & Helm - Visual Learning Guide

## 1ï¸âƒ£ What is Kubernetes?

```
Your Application (in containers)
         â†“
    Kubernetes (Orchestrator)
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â€¢ Runs containers          â”‚
    â”‚  â€¢ Scales automatically     â”‚
    â”‚  â€¢ Heals failed pods        â”‚
    â”‚  â€¢ Networks containers      â”‚
    â”‚  â€¢ Manages storage          â”‚
    â”‚  â€¢ Updates without downtime â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2ï¸âƒ£ Key Kubernetes Objects

### Pod (Smallest Unit)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Pod            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Container   â”‚  â”‚
â”‚  â”‚ (Docker/Node) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service (Network)

```
         Service
    (DNS entry + Load Balancer)
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚
  Pod 1    Pod 2    Pod 3
```

### Deployment (Manage Pods)

```
Deployment
    â”œâ”€ Replica 1 â”€â†’ Pod
    â”œâ”€ Replica 2 â”€â†’ Pod
    â”œâ”€ Replica 3 â”€â†’ Pod
    â””â”€ Auto-scales based on load
```

### StatefulSet (Stateful Apps)

```
StatefulSet
    â”œâ”€ postgres-0  â”€â†’ Pod (stable name)
    â”œâ”€ postgres-1  â”€â†’ Pod (persistent storage)
    â””â”€ postgres-2  â”€â†’ Pod (ordered startup)
```

---

## 3ï¸âƒ£ Your TikTok Clone Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Users (Internet)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                     â”‚
        â–¼                                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ API Gateway â”‚                    â”‚ Frontend   â”‚
   â”‚ Service     â”‚â—„â”€â”€â”€â”€callsâ”€â”€â”€â”€â–º     â”‚ (Next.js)  â”‚
   â”‚ (4000)      â”‚                    â”‚ (3000)     â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     â”‚         â”‚      â”‚        â”‚
    â–¼     â–¼         â–¼      â–¼        â–¼
  â”Œâ”€â”€â”  â”Œâ”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”    gRPC communication
  â”‚ASâ”‚  â”‚VSâ”‚  â”‚Inter â”‚ â”‚Notifâ”‚   (microservices)
  â”‚  â”‚  â”‚  â”‚  â”‚Svc   â”‚ â”‚Svc  â”‚
  â””â”€â”€â”˜  â””â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
    â”‚     â”‚      â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚       â”‚        â”‚
    â–¼                â–¼       â–¼        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”
  â”‚PostgreSQLâ”‚  â”‚ Redis  â”‚ â”‚Kafka â”‚ â”‚ ...  â”‚
  â”‚  (Data)  â”‚  â”‚(Cache) â”‚ â”‚ (Msg)â”‚ â”‚      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points**:

- Services find each other by name: `auth-service.tiktok-clone.svc.cluster.local`
- gRPC for internal communication (fast, binary)
- HTTP/REST for external APIs
- Database & Cache shared by all services

---

## 4ï¸âƒ£ ConfigMap & Secret (Configuration)

### Without ConfigMap/Secret (âŒ Bad)

```
Service Code:
    const dbHost = "auth-service-db-prod-server";
    const dbPort = 5432;
    const dbPassword = "super-secret-123";

Problem: Hardcoded! Can't change without rebuilding image
```

### With ConfigMap/Secret (âœ… Good)

```
ConfigMap (tiktok-db-config):
    DB_HOST: postgres.tiktok-clone.svc.cluster.local
    DB_PORT: 5432
    DB_NAME: tiktok_clone

Secret (tiktok-db-secrets):
    DB_PASSWORD: (base64 encoded)
    JWT_ACCESS_SECRET: (base64 encoded)

Service Code:
    const dbHost = process.env.DB_HOST;      // From ConfigMap
    const dbPassword = process.env.DB_PASSWORD; // From Secret

Benefit: Change config without rebuilding!
```

### Environment Injection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Container starts   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Load env    â”‚
    â”‚ from:       â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚ â”‚ConfigMPâ”‚  â”‚
    â”‚ â”‚Secret  â”‚  â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Available inside     â”‚
    â”‚ container:           â”‚
    â”‚ DB_HOST, DB_PASSWORD â”‚
    â”‚ JWT_ACCESS_SECRET... â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5ï¸âƒ£ Helm Templating

### Helm Template Flow

```
values.yaml
    â”‚
    â”œâ”€ postgresql:
    â”‚   auth:
    â”‚     password: "postgres"
    â”‚
    â”œâ”€ services:
    â”‚   auth:
    â”‚     replicas: 2
    â”‚     port: 4001
    â””â”€ ...
         â”‚
         â–¼
    Helm Template Engine
         â”‚
    â”œâ”€ {{ .Values.postgresql.auth.password }}
    â”‚  becomes: "postgres"
    â”‚
    â”œâ”€ {{ if .Values.postgresql.enabled }}
    â”‚  conditionally include postgres
    â”‚
    â””â”€ {{ range .Values.services }}
       loop through each service
         â”‚
         â–¼
    Generated K8s Manifests (YAML)
         â”‚
         â–¼
    kubectl apply
         â”‚
         â–¼
    Kubernetes Cluster
         â”‚
         â–¼
    Running Pods âœ…
```

### Before/After Example

**Before (hardcoded - k8s/services/auth-service.yaml)**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 2 # â† Hardcoded! Can't change
  template:
    spec:
      containers:
        - image: tiktok-auth-service:latest
          ports:
            - containerPort: 4001 # â† Hardcoded!
          env:
            - name: PORT
              value: '4001' # â† Hardcoded!
```

**After (templated - helm/templates/auth-service.yaml)**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: { { .Values.services.auth.name } }
spec:
  replicas: { { .Values.services.auth.replicas } } # â† From values!
  template:
    spec:
      containers:
        - image: '{{ .Values.services.auth.image.repository }}:{{ .Values.services.auth.image.tag }}'
          ports:
            - containerPort: { { .Values.services.auth.port } } # â† From values!
          env:
            - name: PORT
              value: { { .Values.services.auth.port | quote } } # â† From values!
```

**Using different values files**:

```
helm install ... -f values.yaml -f values-dev.yaml
      â†“
values.yaml: replicas: 2
values-dev.yaml: replicas: 1
      â†“
Final value: 1 âœ… (dev override wins)

helm install ... -f values.yaml -f values-prod.yaml
      â†“
values.yaml: replicas: 2
values-prod.yaml: replicas: 3
      â†“
Final value: 3 âœ… (prod override wins)
```

---

## 6ï¸âƒ£ Pod Lifecycle & Health Checks

### Pod Starting

```
1. Pod created
         â†“
2. Image pulled from registry
         â†“
3. Container starts
         â†“
4. Application initializes (connects to DB, etc.)
         â†“
5. Readiness probe runs: GET /health
    â”œâ”€ Success (200 OK) â†’ Pod becomes ready
    â””â”€ Failure â†’ Retry (5s, then mark not ready)
         â†“
6. Service starts sending traffic
```

### Health Probes

```
Readiness Probe (Can I receive traffic?)
    â”œâ”€ Runs every 5 seconds
    â”œâ”€ Check: GET /health
    â”œâ”€ If fails â†’ Remove from load balancer
    â””â”€ Pod still alive, just not receiving traffic

Liveness Probe (Is the pod alive?)
    â”œâ”€ Runs every 10 seconds
    â”œâ”€ Check: GET /health
    â”œâ”€ If fails for 3 times â†’ RESTART pod
    â””â”€ Automatic recovery from crashes
```

### Pod States

```
Pending â†’ Container init
   â†“
Running â†’ Healthy & ready
   â”œâ”€ Receives traffic âœ…
   â”‚
   â””â”€ CrashLoopBackOff
      â””â”€ Application crashing, K8s retrying
         â””â”€ Check logs: kubectl logs {pod}

      â””â”€ ImagePullBackOff
         â””â”€ Docker image not found
         â””â”€ Build image or fix image name

      â””â”€ ErrImagePull
         â””â”€ Registry unreachable
         â””â”€ Check image URL, registry creds
```

---

## 7ï¸âƒ£ Service Discovery

### How Services Find Each Other

**Inside a Pod**:

```
Container A needs to call Auth Service

1. Container: curl http://auth-service:4001/health
2. DNS: What's the IP of "auth-service"?
3. CoreDNS (K8s DNS): 10.5.123.45
4. Request: 10.5.123.45:4001 âœ…
5. Service: Routes to Pod 1, Pod 2, or Pod 3 (load balanced)
6. Response âœ…
```

**DNS Names**:

```
Short name (same namespace):
    postgres
    redis
    auth-service

Full name (any namespace):
    postgres.tiktok-clone.svc.cluster.local
    redis.tiktok-clone.svc.cluster.local
    auth-service.tiktok-clone.svc.cluster.local

Format:
    {service}.{namespace}.svc.cluster.local
```

**Behind the Scenes**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service: auth-service               â”‚
â”‚  - Port: 4001                       â”‚
â”‚  - Selector: app: auth-service      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
           â”‚                        â”‚
         Load Balancing            Pod Selection
           â”‚                        â”‚
           â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ kubernetes     â”‚   â”‚ Find all Pods with   â”‚
    â”‚ kube-proxy     â”‚   â”‚ label: app=auth-svc  â”‚
    â”‚ distributes    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ traffic        â”‚            â†“
    â”‚ Round-robin    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ auth-pod-1: 10.1     â”‚
                         â”‚ auth-pod-2: 10.2     â”‚
                         â”‚ auth-pod-3: 10.3     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8ï¸âƒ£ Scaling & Auto-Scaling

### Manual Scaling

```
kubectl scale deployment auth-service --replicas=5

Before:                After:
â”Œâ”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”
â”‚pod1â”‚                 â”‚pod1â”‚
â”œâ”€â”€â”€â”€â”¤                 â”œâ”€â”€â”€â”€â”¤
â”‚pod2â”‚                 â”‚pod2â”‚
â”œâ”€â”€â”€â”€â”¤                 â”œâ”€â”€â”€â”€â”¤
â”‚    â”‚                 â”‚pod3â”‚
     â”œâ”€â”€â”€â”€â”¤           â”œâ”€â”€â”€â”€â”¤
     â”‚pod4â”‚
     â”œâ”€â”€â”€â”€â”¤
     â”‚pod5â”‚
     â””â”€â”€â”€â”€â”˜

Replicas: 2 â†’ 5
```

### Auto-Scaling (HPA)

```
HPA: Horizontal Pod Autoscaler

Monitor CPU/Memory:
    â”œâ”€ High load (CPU > 70%)
    â”‚   â””â”€ Scale UP (add pods)
    â”‚
    â””â”€ Low load (CPU < 30%)
        â””â”€ Scale DOWN (remove pods)

Example: auth-service
    â”œâ”€ Min: 2 pods
    â”œâ”€ Max: 5 pods
    â””â”€ Target CPU: 70%

Load increases:
    Step 1: Current 2 pods, CPU = 85% (> 70%)
    Step 2: Scale to 3 pods
    Step 3: Wait 3 minutes
    Step 4: CPU = 72% (still > 70%)
    Step 5: Scale to 4 pods
    ... repeat until CPU < 70%
```

---

## 9ï¸âƒ£ Deployment Strategy

### Rolling Update (Default)

```
Version 1 â†’ Version 2 (gradual replacement)

Old:  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
      â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ (3 pods)
      â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
         â†“
      â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
      â”‚ v2  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ (1 updated)
      â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
         â†“
      â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
      â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v1  â”‚ (2 updated)
      â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
         â†“
      â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
      â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v2  â”‚ (3 updated)
      â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

No downtime! Gradual transition.
If new version fails, rollback automatically.
```

---

## ðŸ”Ÿ Your Deployment Workflow

### Step 1: Create Images

```
Source Code â†’ Docker Build â†’ Image â†’ Registry
                    â†“
        tiktok-auth-service:latest
        tiktok-video-service:latest
        ... etc
```

### Step 2: Create K8s Resources

```
Helm values + templates â†’ Generated manifests â†’ kubectl apply
                              â†“
                        postgres.yaml
                        redis.yaml
                        auth-service.yaml
                        ... etc
```

### Step 3: Pods Start

```
Manifest applied â†’ Pod created â†’ Container starts
                                      â†“
                            Application initialization
                                      â†“
                            Readiness probe â†’ Ready âœ…
```

### Step 4: Services Connect

```
ConfigMap injected â†’ Services get DB host
       â†“
       postgres.tiktok-clone.svc.cluster.local:5432
       â†“
       Connection established âœ…
```

### Step 5: Traffic Flows

```
Client â†’ LoadBalancer (api-gateway)
           â†“
        Service (distributes traffic)
           â†“
        â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”
        â†“         â†“  â†“
      pod1      pod2 pod3
                    â†“
      Response to client âœ…
```

---

## ðŸŽ¯ Summary

**Key Takeaways**:

1. âœ… **Pod** = Container wrapper
2. âœ… **Service** = Stable DNS + load balancer
3. âœ… **Deployment** = Manage pod replicas
4. âœ… **ConfigMap** = Configuration (non-sensitive)
5. âœ… **Secret** = Sensitive data (passwords)
6. âœ… **Helm** = Template engine + version control
7. âœ… **HPA** = Automatic scaling
8. âœ… **Health Checks** = Automatic recovery
9. âœ… **Service Discovery** = DNS inside cluster
10. âœ… **Rolling Updates** = Zero-downtime deployments

---

**Next**: Read `KUBERNETES_HELM_SETUP.md` for detailed implementation! ðŸš€
